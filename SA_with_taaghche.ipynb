{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning models for classifing persion language dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I worked with simple machine learning models, naive bayes and svm for sentiment analysis with the persian language dataset, taaghche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we are using persian dataset, we need some libraries for preprocessing the data before using it. we need hazm package which is one of the famous libraries for tokenizing text, lemmatization and other preprocessing task. for removing stopwords in persian we can use guilannlp stopwords, so lets install them first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in c:\\users\\it man\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in c:\\users\\it man\\anaconda3\\lib\\site-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\it man\\anaconda3\\lib\\site-packages (from nltk==3.3->hazm) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stopwords_guilannlp\n",
      "  Downloading stopwords_guilannlp-13.2019.3.5-py3-none-any.whl (8.2 kB)\n",
      "Installing collected packages: stopwords-guilannlp\n",
      "Successfully installed stopwords-guilannlp-13.2019.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install stopwords_guilannlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some installation we need to import some libraries that are usable for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Preprocessing\n",
    "from stopwords_guilannlp import stopwords_output\n",
    "from hazm import *\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Measuring metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets look at the dataset\n",
    "taghche dataset is the collection of book reviews which have polarities from 0 to 5. like some other datasets there are some problems so we need preprocesing. first we load the dataset using pandas library and look at the structure of dataset by calling the first 5 rows of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>bookname</th>\n",
       "      <th>rate</th>\n",
       "      <th>bookID</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1395/11/14</td>\n",
       "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
       "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1395/11/14</td>\n",
       "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
       "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394/06/06</td>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393/09/02</td>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1393/06/29</td>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>سرهنگ کسی ندارد برایش نامه بنویسد</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                            comment  \\\n",
       "0  1395/11/14  اسم کتاب   No one writes to the Colonel\\nترجمش...   \n",
       "1  1395/11/14  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   \n",
       "2  1394/06/06  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   \n",
       "3  1393/09/02  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   \n",
       "4  1393/06/29                                      کتاب خوبی است   \n",
       "\n",
       "                            bookname  rate  bookID  like  \n",
       "0  سرهنگ کسی ندارد برایش نامه بنویسد   0.0     3.0   2.0  \n",
       "1  سرهنگ کسی ندارد برایش نامه بنویسد   5.0     3.0   2.0  \n",
       "2  سرهنگ کسی ندارد برایش نامه بنویسد   5.0     3.0   0.0  \n",
       "3  سرهنگ کسی ندارد برایش نامه بنویسد   2.0     3.0   0.0  \n",
       "4  سرهنگ کسی ندارد برایش نامه بنویسد   3.0     3.0   0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"taghche.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we dont need columns like date, bookname, bookID and like we can drop them from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rate\n",
       "0  اسم کتاب   No one writes to the Colonel\\nترجمش...   0.0\n",
       "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   5.0\n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   5.0\n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   2.0\n",
       "4                                      کتاب خوبی است   3.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('date', inplace=True, axis=1)\n",
    "df.drop('bookname', inplace=True, axis=1)\n",
    "df.drop('bookID', inplace=True, axis=1)\n",
    "df.drop('like', inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69829 entries, 0 to 69828\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   comment  69808 non-null  object \n",
      " 1   rate     69790 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are some conflicts and some part of the dataset is null and there are some missing values and duplicated raws, so we should fix them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_values_stat:\n",
      "comment    21\n",
      "rate       39\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"missing_values_stat:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for skipping null values we can use dropna() and then for removing some duplicates that may happen we use drop_duplicate and then reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.dropna(subset=['comment'])\n",
    "data = data.dropna(subset=['rate'])\n",
    "data = data.drop_duplicates(subset=['comment'], keep='first')\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_values_stat:\n",
      "comment    0\n",
      "rate       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"missing_values_stat:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have #21: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2932.0, 4206.0, 4385.0, 10053.0, 12836.0, 13482.0, 15965.0, 17152.0, 22694.0, 28912.0, 38473.0, 38591.0, 41097.0, 42368.0, 54374.0]\n"
     ]
    }
   ],
   "source": [
    "unique_rates = list(sorted(data['rate'].unique()))\n",
    "print(f'We have #{len(unique_rates)}: {unique_rates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we could guess there are some other rates which are more than 5 in the rate columns of our dataset, so we need to skip the rows with the rate of more than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rate\n",
       "0  اسم کتاب   No one writes to the Colonel\\nترجمش...   0.0\n",
       "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   5.0\n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   5.0\n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   2.0\n",
       "4                                      کتاب خوبی است   3.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['rate'] <= 5]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have #6: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "unique_rates = list(sorted(data['rate'].unique()))\n",
    "print(f'We have #{len(unique_rates)}: {unique_rates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for the binary classification and for simplicity we can transform rates to a binary form of 0 with the rates of less than a threshold and 1 with rates of more than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rate\n",
       "0  اسم کتاب   No one writes to the Colonel\\nترجمش...   0.0\n",
       "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   1.0\n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   1.0\n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   0.0\n",
       "4                                      کتاب خوبی است   1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rate_to_label(rate, threshold=3.0):\n",
    "  if rate < threshold:\n",
    "    return 0.0\n",
    "  else:\n",
    "   return 1.0\n",
    "\n",
    "data['rate'] = data['rate'].apply(lambda t: rate_to_label(t, 3.0))\n",
    "labels = list(sorted(data['rate'].unique()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can do some cleaning, removing HTML tags, some patterns and emojies and normalizing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clean-text in c:\\users\\it man\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\it man\\anaconda3\\lib\\site-packages (from clean-text) (6.0.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\it man\\anaconda3\\lib\\site-packages (from clean-text) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\it man\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHTML(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "def cleaning(text):\n",
    "    text = text.strip()\n",
    "    \n",
    "    # regular cleaning\n",
    "    text = clean(text,\n",
    "        fix_unicode=True,\n",
    "        to_ascii=False,\n",
    "        lower=True,\n",
    "        no_line_breaks=True,\n",
    "        no_urls=True,\n",
    "        no_emails=True,\n",
    "        no_phone_numbers=True,\n",
    "        no_numbers=False,\n",
    "        no_digits=False,\n",
    "        no_currency_symbols=True,\n",
    "        no_punct=False,\n",
    "        replace_with_url=\"\",\n",
    "        replace_with_email=\"\",\n",
    "        replace_with_phone_number=\"\",\n",
    "        replace_with_number=\"\",\n",
    "        replace_with_digit=\"0\",\n",
    "        replace_with_currency_symbol=\"\",\n",
    "    )\n",
    "     # cleaning htmls\n",
    "    text = cleanHTML(text)\n",
    "    \n",
    "    # normalizing\n",
    "    normalizer = Normalizer()\n",
    "    text = normalizer.normalize(text)\n",
    "    \n",
    "    # removing wierd patterns\n",
    "    wierd_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u'\\U00010000-\\U0010ffff'\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\u3030\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u2069\"\n",
    "        u\"\\u2066\"\n",
    "        # u\"\\u200c\"\n",
    "        u\"\\u2068\"\n",
    "        u\"\\u2067\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    text = wierd_pattern.sub(r'', text)\n",
    "    \n",
    "    # removing extra spaces, hashtags\n",
    "    text = re.sub(\"#\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اسم کتاب   No one writes to the Colonel\\nترجمش...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>اسم کتاب no one writes to the colonel ترجمش می...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>1.0</td>\n",
       "      <td>کتاب خوبی است</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rate  \\\n",
       "0  اسم کتاب   No one writes to the Colonel\\nترجمش...   0.0   \n",
       "1  طاقچه عزیز،نام کتاب\"کسی به سرهنگ نامه نمینویسد...   1.0   \n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   1.0   \n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   0.0   \n",
       "4                                      کتاب خوبی است   1.0   \n",
       "\n",
       "                                     cleaned_comment  \n",
       "0  اسم کتاب no one writes to the colonel ترجمش می...  \n",
       "1  طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...  \n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...  \n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...  \n",
       "4                                      کتاب خوبی است  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_comment'] = data['comment'].apply(cleaning)\n",
    "data = data.dropna(subset=['cleaned_comment'])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اسم کتاب no one writes to the colonel ترجمش می...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کتاب خوبی است</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cleaned_comment  rate\n",
       "0  اسم کتاب no one writes to the colonel ترجمش می...   0.0\n",
       "1  طاقچه عزیز، نام کتاب «کسی به سرهنگ نامه نمینوی...   1.0\n",
       "2  بنظرم این اثر مارکز خیلی از صد سال تنهایی که ب...   1.0\n",
       "3  به نظر کتاب خوبی میومد اما من از ترجمش خوشم نی...   0.0\n",
       "4                                      کتاب خوبی است   1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['cleaned_comment','rate']]\n",
    "data.columns = ['cleaned_comment','rate']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can randomly sample dataset based on the fewer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26360 entries, 0 to 26359\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cleaned_comment  26360 non-null  object \n",
      " 1   rate             26360 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 412.0+ KB\n"
     ]
    }
   ],
   "source": [
    "negative_data = data[data['rate'] == 0.0]\n",
    "positive_data = data[data['rate'] == 1.0]\n",
    "cutting_point = min(len(negative_data), len(positive_data))\n",
    "if cutting_point <= len(negative_data):\n",
    "  negative_data = negative_data.sample(n=cutting_point).reset_index(drop=True)\n",
    "if cutting_point <= len(positive_data):\n",
    "    positive_data = positive_data.sample(n=cutting_point).reset_index(drop=True)\n",
    "new_data = pd.concat([negative_data, positive_data])\n",
    "new_data = new_data.sample(frac=1).reset_index(drop=True)\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نامه‌ای به داروین...... سلام جناب داروین! … می...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>یک ستاره؛ برای اینکه کتاب گویا با نمایش رادیوی...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>یه عاشقانه خیلی معمولی ولی چون من- دختری ک رها...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بسیار خوب و آموزنده بود</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aliii</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cleaned_comment  rate\n",
       "0  نامه‌ای به داروین...... سلام جناب داروین! … می...   0.0\n",
       "1  یک ستاره؛ برای اینکه کتاب گویا با نمایش رادیوی...   0.0\n",
       "2  یه عاشقانه خیلی معمولی ولی چون من- دختری ک رها...   1.0\n",
       "3                            بسیار خوب و آموزنده بود   1.0\n",
       "4                                              aliii   1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have #2: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "unique_rates = list(sorted(new_data['rate'].unique()))\n",
    "print(f'We have #{len(unique_rates)}: {unique_rates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split dataset into 3 parts, train, validation and test set. for this purpose we use sklearn package, we use the rate of 0.2 for both valid and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16870, 3)\n",
      "(4218, 3)\n",
      "(5272, 3)\n"
     ]
    }
   ],
   "source": [
    "new_data['rate_id'] = new_data['rate'].apply(lambda t: labels.index(t))\n",
    "train, test = train_test_split(new_data, test_size=0.2, stratify= new_data['rate'])\n",
    "train, valid = train_test_split(train, test_size=0.2, stratify= train['rate'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "x_train, y_train = train['cleaned_comment'].values.tolist(), train['rate_id'].values.tolist()\n",
    "x_valid, y_valid = valid['cleaned_comment'].values.tolist(), valid['rate_id'].values.tolist()\n",
    "x_test, y_test = test['cleaned_comment'].values.tolist(), test['rate_id'].values.tolist()\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed data into the model we can change the type of data from dataframe to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_numpy()\n",
    "valid = valid.to_numpy()\n",
    "test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "now its time to define our ML model, here I used a simple naive bayse and svm model, with tf-idf vectorizer for transforming and vectorizing the cleaned and preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "min_df = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model:  0.7659332321699545\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = Pipeline([('vect', CountVectorizer(tokenizer=tokenize,\n",
    "                                              analyzer='word', ngram_range=(1, 2), min_df=min_df, lowercase=False)),\n",
    "                     ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                     ('clf', MultinomialNB())])\n",
    "naive_bayes = naive_bayes.fit(x_train, y_train)\n",
    "naive_score = naive_bayes.score(x_test, y_test)\n",
    "print('Naive Bayes Model: ', naive_score)\n",
    "predict_nb = naive_bayes.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model\n",
    "we can examine a svm model to check and compare these 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT Man\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Model:  0.756638846737481\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline([('vect', CountVectorizer(tokenizer=tokenize,\n",
    "                                                         analyzer='word', ngram_range=(1, 2),\n",
    "                                                         min_df=min_df, lowercase=False)),\n",
    "                                ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                                ('clf-svm', LinearSVC(loss='hinge', penalty='l2',\n",
    "                                                      max_iter=5))])\n",
    "\n",
    "svm = svm.fit(x_train, y_train)\n",
    "linear_svc_score = svm.score(x_test, y_test)\n",
    "print('Linear SVC Model: ', linear_svc_score)\n",
    "predict_svm = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of NB model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.765913827447639"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"F1 score of NB model:\")\n",
    "f1_score(y_test, predict_nb, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of SVM model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7565813857585859"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"F1 score of SVM model:\")\n",
    "f1_score(y_test, predict_svm, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the preprocessing part was super inspired by: https://github.com/hooshvare/parsbert/tree/master/notebooks.\n",
    "###### taaghche dataset is available at https://www.kaggle.com/saeedtqp/taaghche"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
